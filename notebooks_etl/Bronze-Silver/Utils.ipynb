{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONEXIÓN MINIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minio import Minio\n",
    "from minio.error import S3Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conectar_minio(endpoint='localhost:9000', \n",
    "                  access_key=None, \n",
    "                  secret_key=None, \n",
    "                  secure=False):\n",
    "    \"\"\"\n",
    "    Establece una conexión con un servidor MinIO.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    endpoint : str, opcional\n",
    "        Dirección del servidor MinIO (por defecto 'localhost:9000')\n",
    "    access_key : str, requerido\n",
    "        Usuario/access key para la autenticación\n",
    "    secret_key : str, requerido\n",
    "        Contraseña/secret key para la autenticación\n",
    "    secure : bool, opcional\n",
    "        Si es True, usa HTTPS. Si es False, usa HTTP (por defecto False)\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    Minio\n",
    "        Cliente MinIO conectado\n",
    "    \n",
    "    Excepciones:\n",
    "    ------------\n",
    "    ValueError\n",
    "        Si no se proporcionan access_key o secret_key\n",
    "    S3Error\n",
    "        Si hay un error al conectar con el servidor MinIO\n",
    "    \"\"\"\n",
    "    \n",
    "    if not access_key or not secret_key:\n",
    "        raise ValueError(\"Se requieren access_key y secret_key para la conexión\")\n",
    "    \n",
    "    try:\n",
    "        # Crear cliente MinIO\n",
    "        cliente = Minio(\n",
    "            endpoint,\n",
    "            access_key=access_key,\n",
    "            secret_key=secret_key,\n",
    "            secure=secure\n",
    "        )\n",
    "        \n",
    "        # Verificar conexión listando los buckets (opcional)\n",
    "        buckets = cliente.list_buckets()\n",
    "        print(f\"Conexión exitosa a MinIO en {endpoint}\")\n",
    "        print(f\"Buckets disponibles: {[bucket.name for bucket in buckets]}\")\n",
    "        \n",
    "        return cliente\n",
    "    \n",
    "    except S3Error as err:\n",
    "        print(f\"Error al conectar con MinIO: {err}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subir archivos Minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO, StringIO\n",
    "import pandas as pd\n",
    "from minio.error import S3Error  # Asegúrate de importar S3Error\n",
    "\n",
    "def guardar_df_en_minio(minio_client, df, bucket_name, ruta_destino, \n",
    "                        formato='parquet', crear_bucket=False):\n",
    "    \"\"\"\n",
    "    Guarda un DataFrame directamente en un bucket de MinIO.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not minio_client:\n",
    "        raise ValueError(\"Se requiere un cliente MinIO válido\")\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"El parámetro df debe ser un pandas.DataFrame\")\n",
    "    if not bucket_name or not ruta_destino:\n",
    "        raise ValueError(\"bucket_name y ruta_destino son requeridos\")\n",
    "    \n",
    "    formatos_soportados = {\n",
    "        'parquet': {\n",
    "            'mime': 'application/parquet',\n",
    "            'writer': lambda buffer: df.to_parquet(buffer, index=False),\n",
    "            'extension': '.parquet',\n",
    "            'buffer_type': BytesIO\n",
    "        },\n",
    "        'csv': {\n",
    "            'mime': 'text/csv',\n",
    "            'writer': lambda buffer: df.to_csv(buffer, index=False),\n",
    "            'extension': '.csv',\n",
    "            'buffer_type': StringIO\n",
    "        },\n",
    "        'json': {\n",
    "            'mime': 'application/json',\n",
    "            'writer': lambda buffer: df.to_json(buffer, orient='records'),\n",
    "            'extension': '.json',\n",
    "            'buffer_type': BytesIO\n",
    "        },\n",
    "        'excel': {\n",
    "            'mime': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n",
    "            'writer': lambda buffer: df.to_excel(buffer, index=False),\n",
    "            'extension': '.xlsx',\n",
    "            'buffer_type': BytesIO\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    formato = formato.lower()\n",
    "    if formato not in formatos_soportados:\n",
    "        raise ValueError(f\"Formato '{formato}' no soportado. Use: {list(formatos_soportados.keys())}\")\n",
    "    \n",
    "    if not ruta_destino.lower().endswith(formatos_soportados[formato]['extension']):\n",
    "        ruta_destino += formatos_soportados[formato]['extension']\n",
    "    \n",
    "    try:\n",
    "        if crear_bucket and not minio_client.bucket_exists(bucket_name):\n",
    "            minio_client.make_bucket(bucket_name)\n",
    "            print(f\"Bucket '{bucket_name}' creado exitosamente\")\n",
    "\n",
    "        if not minio_client.bucket_exists(bucket_name):\n",
    "            raise S3Error(f\"El bucket '{bucket_name}' no existe\", bucket_name, None, 404)\n",
    "        \n",
    "        # Crear buffer en memoria\n",
    "        buffer = formatos_soportados[formato]['buffer_type']()\n",
    "        formatos_soportados[formato]['writer'](buffer)\n",
    "\n",
    "        # Ajuste para CSV (convertir a BytesIO)\n",
    "        if formato == 'csv':\n",
    "            buffer.seek(0)\n",
    "            data = BytesIO(buffer.getvalue().encode('utf-8'))\n",
    "            length = len(data.getvalue())\n",
    "        else:\n",
    "            buffer.seek(0)\n",
    "            data = buffer\n",
    "            length = buffer.getbuffer().nbytes\n",
    "        \n",
    "        # Subir a MinIO\n",
    "        minio_client.put_object(\n",
    "            bucket_name=bucket_name,\n",
    "            object_name=ruta_destino,\n",
    "            data=data,\n",
    "            length=length,\n",
    "            content_type=formatos_soportados[formato]['mime']\n",
    "        )\n",
    "        \n",
    "        ruta_completa = f\"{bucket_name}/{ruta_destino}\"\n",
    "        print(f\"DataFrame guardado exitosamente en: {ruta_completa}\")\n",
    "        return ruta_completa\n",
    "\n",
    "    except S3Error as err:\n",
    "        print(f\"Error al guardar DataFrame en MinIO: {err}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar el DataFrame: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leer archivo desde minio Minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import docx\n",
    "\n",
    "def extraer_archivo_minio(minio_client, bucket_name, ruta_archivo, tipo_archivo):\n",
    "    \"\"\"\n",
    "    Extrae un archivo de MinIO y lo retorna en el formato adecuado.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    minio_client : Minio\n",
    "        Cliente MinIO ya conectado\n",
    "    bucket_name : str\n",
    "        Nombre del bucket donde está el archivo\n",
    "    ruta_archivo : str\n",
    "        Ruta completa del archivo dentro del bucket\n",
    "    tipo_archivo : str\n",
    "        Tipo de archivo a extraer ('pdf', 'word', 'excel', 'csv', 'parquet')\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    Depende del tipo de archivo:\n",
    "    - 'pdf': Texto extraído (str)\n",
    "    - 'word': Documento de python-docx\n",
    "    - 'excel': DataFrame de pandas\n",
    "    - 'csv': DataFrame de pandas\n",
    "    - 'parquet': DataFrame de pandas\n",
    "    \n",
    "    Excepciones:\n",
    "    ------------\n",
    "    ValueError\n",
    "        Si los parámetros son inválidos o el tipo no es soportado\n",
    "    S3Error\n",
    "        Si hay un error al acceder al archivo o el bucket no existe\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validaciones iniciales\n",
    "    if not minio_client:\n",
    "        raise ValueError(\"Se requiere un cliente MinIO válido\")\n",
    "    if not bucket_name or not ruta_archivo or not tipo_archivo:\n",
    "        raise ValueError(\"bucket_name, ruta_archivo y tipo_archivo son requeridos\")\n",
    "    \n",
    "    tipo_archivo = tipo_archivo.lower()\n",
    "    tipos_soportados = ['pdf', 'word', 'excel', 'csv', 'parquet']\n",
    "    \n",
    "    if tipo_archivo not in tipos_soportados:\n",
    "        raise ValueError(f\"Tipo de archivo '{tipo_archivo}' no soportado. Use: {tipos_soportados}\")\n",
    "    \n",
    "    try:\n",
    "        # Obtener el objeto de MinIO\n",
    "        response = minio_client.get_object(bucket_name, ruta_archivo)\n",
    "        data = BytesIO(response.read())\n",
    "        data.seek(0)\n",
    "        \n",
    "        # Procesar según el tipo de archivo\n",
    "        if tipo_archivo == 'pdf':\n",
    "            # Extraer texto de PDF\n",
    "            pdf_reader = PyPDF2.PdfReader(data)\n",
    "            text = \"\\n\".join([page.extract_text() for page in pdf_reader.pages])\n",
    "            return text\n",
    "        \n",
    "        elif tipo_archivo == 'word':\n",
    "            # Retornar documento de Word\n",
    "            return docx.Document(data)\n",
    "        \n",
    "        elif tipo_archivo in ['excel', 'csv', 'parquet']:\n",
    "            # Leer con pandas según el formato\n",
    "            if tipo_archivo == 'excel':\n",
    "                return pd.read_excel(data)\n",
    "            elif tipo_archivo == 'csv':\n",
    "                return pd.read_csv(data)\n",
    "            elif tipo_archivo == 'parquet':\n",
    "                return pd.read_parquet(data)\n",
    "        \n",
    "    except S3Error as err:\n",
    "        print(f\"Error al acceder al archivo en MinIO: {err}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar el archivo {ruta_archivo}: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        response.close()\n",
    "        response.release_conn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar ruta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def generar_ruta_fecha(separador='/', fecha=None):\n",
    "    \"\"\"\n",
    "    Genera un string con la fecha en formato año/mes/día.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    separador : str, opcional\n",
    "        Carácter separador entre componentes (por defecto '/')\n",
    "    fecha : datetime, opcional\n",
    "        Fecha específica a formatear (si None, usa fecha actual)\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    str\n",
    "        String con el formato 'YYYY{separador}MM{separador}DD'\n",
    "    \"\"\"\n",
    "    # Usar fecha actual si no se proporciona una específica\n",
    "    fecha_a_usar = fecha if fecha is not None else datetime.now()\n",
    "    \n",
    "    # Formatear la fecha\n",
    "    ruta_fecha = fecha_a_usar.strftime(f\"%Y{separador}%m{separador}%d\")\n",
    "    \n",
    "    return ruta_fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025/05/05\n"
     ]
    }
   ],
   "source": [
    "ruta = generar_ruta_fecha()\n",
    "print(ruta)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_special_characters(text):\n",
    "    \"\"\"\n",
    "    Limpia caracteres especiales y no deseados en un texto o lista de textos.\n",
    "\n",
    "    Args:\n",
    "        text (str | list): Texto o lista de textos a limpiar.\n",
    "\n",
    "    Returns:\n",
    "        str: Texto limpio.\n",
    "    \"\"\"\n",
    "    if isinstance(text, list):\n",
    "        # Si es una lista, convertirla en una sola cadena separada por espacios\n",
    "        text = ' '.join(text)\n",
    "    \n",
    "    if isinstance(text, str):\n",
    "        # Reemplazar \\uf0d8 con viñeta estándar\n",
    "        text = text.replace('\\uf0d8', '•')\n",
    "        # Eliminar corchetes y otros caracteres especiales\n",
    "        text = re.sub(r'[\\[\\]\\\"]', '', text)\n",
    "        # Eliminar caracteres no ASCII imprimibles\n",
    "        text = re.sub(r'[^\\x20-\\x7E]', '', text)\n",
    "        return text.strip()  # Eliminar espacios en blanco adicionales\n",
    "\n",
    "    return text  # Si no es cadena ni lista, devolver sin cambios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_points(text):\n",
    "    \"\"\"\n",
    "    Remueve los puntos de un texto.\n",
    "\n",
    "    Parámetros:\n",
    "    - text (str o list): Texto a limpiar.\n",
    "\n",
    "    Retorno:\n",
    "    - str: Texto limpio.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, (str, list)):\n",
    "        raise ValueError(\"El texto debe ser una cadena o una lista\")\n",
    "\n",
    "    if isinstance(text, list):\n",
    "        text = ' '.join(text)\n",
    "\n",
    "    return text.replace('.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateparser\n",
    "def transformate_date(date):\n",
    "    \"\"\"\n",
    "    Transforma una fecha en el formato 'Enero 10 de 2024' a '30/12/2022'.\n",
    "\n",
    "    Parámetros:\n",
    "    - fecha (str): Fecha a transformar.\n",
    "\n",
    "    Retorno:\n",
    "    - str: Fecha transformada.\n",
    "    \"\"\"\n",
    "    fecha_parseada = dateparser.parse(date)\n",
    "    if fecha_parseada:\n",
    "        return fecha_parseada.strftime('%d/%m/%Y')\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformar_tipo_identificacion(df):\n",
    "    \"\"\"\n",
    "    Transforma la columna 'TipoIdentificacion' según la edad y crea una nueva columna 'id_paciente'.\n",
    "\n",
    "    Parámetros:\n",
    "    - df (DataFrame): DataFrame que contiene las columnas 'edad', 'Identificacion' y 'TipoIdentificacion'.\n",
    "\n",
    "    Retorno:\n",
    "    - df (DataFrame): DataFrame modificado con la nueva columna 'id_paciente'.\n",
    "    \"\"\"\n",
    "    df['Edad'] = df['Edad'].astype(int)\n",
    "    # Asignar 'CC' o 'TI' según la edad\n",
    "    df.loc[df['Edad'] >= 18, 'TipoIdentificacion'] = 'CC'\n",
    "    df.loc[df['Edad'] < 18, 'TipoIdentificacion'] = 'TI'\n",
    "    # Renombrar la columna 'Identificacion'\n",
    "    df.rename(columns={'Identificacion': 'NumeroIdentificacion'}, inplace=True)\n",
    "    df['TipoIdentificacion'] = df['TipoIdentificacion'].astype(str)  # Asegurarse de que sea una cadena\n",
    "    df['NumeroIdentificacion'] =df['NumeroIdentificacion'].astype(str)  # Asegurarse de que sea una cadena\n",
    "    # Crear la nueva columna 'id_paciente' concatenando 'TipoIdentificacion' y 'NumeroIdentificacion'\n",
    "    df['id_paciente'] = df['TipoIdentificacion'] + df['NumeroIdentificacion']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_columns(table_name, connection_params):\n",
    "    \"\"\"\n",
    "    Obtiene las columnas de una tabla en PostgreSQL.\n",
    "\n",
    "    Args:\n",
    "        table_name (str): Nombre de la tabla en PostgreSQL.\n",
    "        connection_params (dict): Parámetros de conexión a PostgreSQL.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista con los nombres de las columnas de la tabla.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**connection_params)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Consultar los nombres de las columnas de la tabla\n",
    "        query = f\"\"\"\n",
    "            SELECT column_name\n",
    "            FROM information_schema.columns\n",
    "            WHERE table_name = '{table_name}';\n",
    "        \"\"\"\n",
    "        cursor.execute(query)\n",
    "        columns = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "        return columns\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al obtener las columnas de la tabla {table_name}: {e}\")\n",
    "        return []\n",
    "    finally:\n",
    "        if conn:\n",
    "            cursor.close()\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_into_info_lab(df, connection_params):\n",
    "    \"\"\"\n",
    "    Inserta los datos de un DataFrame en la tabla 'infolab' de PostgreSQL,\n",
    "    considerando solo las columnas que coincidan entre los nombres del DataFrame y los de la tabla.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con los datos a insertar.\n",
    "        connection_params (dict): Diccionario con los parámetros de conexión a PostgreSQL.\n",
    "    \"\"\"\n",
    "    # Obtener las columnas de la tabla 'infolab'\n",
    "    table_columns = get_table_columns('infolab', connection_params)\n",
    "    \n",
    "    if not table_columns:\n",
    "        raise ValueError(\"No se pudieron obtener las columnas de la tabla 'infolab'.\")\n",
    "\n",
    "    # Seleccionar las columnas que coincidan entre el DataFrame y la tabla\n",
    "    matching_columns = [col for col in df.columns if col in table_columns]\n",
    "    \n",
    "    if not matching_columns:\n",
    "        raise ValueError(\"No hay columnas coincidentes entre el DataFrame y la tabla 'infolab'.\")\n",
    "\n",
    "    # Conexión a PostgreSQL\n",
    "    try:\n",
    "        conn = psycopg2.connect(**connection_params)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Crear la consulta INSERT dinámica\n",
    "        columns_str = \", \".join(matching_columns)\n",
    "        placeholders_str = \", \".join([\"%s\"] * len(matching_columns))\n",
    "        insert_query = f\"INSERT INTO infolab ({columns_str}) VALUES ({placeholders_str})\"\n",
    "\n",
    "        # Preparar los datos para la inserción\n",
    "        values = df[matching_columns].values.tolist()\n",
    "\n",
    "        # Ejecutar la consulta\n",
    "        cursor.executemany(insert_query, values)\n",
    "        conn.commit()\n",
    "\n",
    "        print(f\"Se insertaron {cursor.rowcount} filas en la tabla 'infolab'.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error al insertar los datos: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        if conn:\n",
    "            cursor.close()\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformate_df(df):\n",
    "    \"\"\"Transforma un DataFrame limpiando caracteres especiales.\"\"\"\n",
    "    try:\n",
    "        # Definir las funciones y columnas a aplicar\n",
    "        df[['Identificacion', 'Numero de Informe', 'Fecha de Informe', 'Fecha de Toma de Muestra', 'Nombre del Paciente']] = df[\n",
    "            ['Identificacion', 'Numero de Informe', 'Fecha de Informe', 'Fecha de Toma de Muestra', 'Nombre del Paciente']].astype(str)\n",
    "        funciones = {\n",
    "            'clean_special_characters': ['Diagnostico'],\n",
    "            'remove_points': ['Identificacion', 'Numero de Informe', 'Fecha de Informe', 'Fecha de Toma de Muestra', 'Nombre del Paciente'],\n",
    "            'transformate_date': ['Fecha de Informe', 'Fecha de Toma de Muestra']\n",
    "        }\n",
    "        \n",
    "        # Aplicar las funciones a las columnas\n",
    "        for funcion, columnas in funciones.items():\n",
    "            for columna in columnas:\n",
    "                df[columna] = df[columna].apply(eval(funcion))\n",
    "        \n",
    "        # Transformar el tipo de identificación\n",
    "        df = transformar_tipo_identificacion(df)\n",
    "        # Renombrar columnas del DataFrame para que coincidan con la tabla en la base de datos\n",
    "        df.rename(columns={\n",
    "            'Fecha de Toma de Muestra': 'fecha_toma_muestra',\n",
    "            'Fecha de Ingreso': 'fecha_ingreso',\n",
    "            'Fecha de Informe': 'fecha_informe',\n",
    "            'Entidad': 'entidad',\n",
    "            'EPS': 'eps',\n",
    "            'Servicio': 'servicio',\n",
    "            'Muestra Remitida': 'muestra_remitida',\n",
    "            'Descripcion Macroscopica': 'descripcion_macroscopica',\n",
    "            'Descripcion Microscopica': 'descripcion_microscopica',\n",
    "            'Diagnostico': 'diagnostico',\n",
    "            'Comentario': 'comentario',\n",
    "            'llavePaciente': 'id_paciente',\n",
    "            'Archivo': 'archivo',\n",
    "            'Historia':'Identificacion'\n",
    "        }, inplace=True)\n",
    "        \n",
    "        # Agregar la columna 'fuente' con un valor por defecto (si es necesario)\n",
    "        df['fuente'] = 'Fernando_sanson'  # Cambia 'nombre_fuente' por el valor que corresponda\n",
    "        return df\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: La columna {e} no se encuentra en el DataFrame.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al momento de transdormar el df: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_entidad_field(entidad):\n",
    "    \"\"\"\n",
    "    Limpia el campo `Entidad` eliminando cualquier información relacionada con\n",
    "    \"FECHA DE INGRESO\" y \"FECHA DE INFORME\".\n",
    "\n",
    "    Args:\n",
    "        entidad (str): Texto del campo `Entidad` a limpiar.\n",
    "\n",
    "    Returns:\n",
    "        str: Texto limpio del campo `Entidad`.\n",
    "    \"\"\"\n",
    "    if not isinstance(entidad, str):\n",
    "        return entidad  # Si no es una cadena, devolver tal cual\n",
    "    \n",
    "    # Expresión regular para encontrar y eliminar las fechas\n",
    "    cleaned_entidad = re.sub(r'FECHA DE INGRESO:.*?(FECHA DE INFORME:.*)?$', '', entidad, flags=re.IGNORECASE).strip()\n",
    "    return cleaned_entidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_identificacion_column(df):\n",
    "    \"\"\"\n",
    "    Divide la columna 'Identificacion' en 'TipoIdentificacion' y 'NumeroIdentificacion',\n",
    "    renombra 'Identificacion' a 'LlavePaciente', y elimina los espacios en 'LlavePaciente'.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con la columna 'Identificacion'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame modificado con las nuevas columnas.\n",
    "    \"\"\"\n",
    "    # Separar los dos primeros caracteres como 'TipoIdentificacion'\n",
    "    df['TipoIdentificacion'] = df['Identificacion'].str[:2].str.strip()\n",
    "    \n",
    "    # Separar el resto del texto como 'NumeroIdentificacion'\n",
    "    df['NumeroIdentificacion'] = df['Identificacion'].str[3:].str.strip()\n",
    "    \n",
    "    # Renombrar la columna 'Identificacion' a 'LlavePaciente'\n",
    "    df.rename(columns={'Identificacion': 'id_paciente'}, inplace=True)\n",
    "    \n",
    "    # Eliminar espacios en 'LlavePaciente' y convertir a minúsculas\n",
    "    df['id_paciente'] = df['id_paciente'].str.replace(r'\\s+', '', regex=True).str.upper()\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformar_df_lab_Jimenez( df):\n",
    "    \"\"\"Trasforma el DataFrame \"\"\"\n",
    "    try:\n",
    "        # limpia la columna \"Entidad\"\n",
    "        df['Entidad'] = df['Entidad'].apply(clean_entidad_field)\n",
    "        # limpia la columna diagnotico\n",
    "        df['Diagnostico'] = df['Diagnostico'].apply(clean_special_characters)\n",
    "        df = process_identificacion_column(df)\n",
    "        # Renombrar columnas del DataFrame para que coincidan con la tabla en la base de datos\n",
    "        df.rename(columns={\n",
    "            'Fecha de Toma de Muestra': 'fecha_toma_muestra',\n",
    "            'Fecha de Ingreso': 'fecha_ingreso',\n",
    "            'Fecha de Informe': 'fecha_informe',\n",
    "            'Entidad': 'entidad',\n",
    "            'EPS': 'eps',\n",
    "            'Servicio': 'servicio',\n",
    "            'Muestra Remitida': 'muestra_remitida',\n",
    "            'Descripcion Macroscopica': 'descripcion_macroscopica',\n",
    "            'Descripcion Microscopica': 'descripcion_microscopica',\n",
    "            'Diagnostico': 'diagnostico',\n",
    "            'Comentario': 'comentario',\n",
    "            'llavePaciente': 'id_paciente',\n",
    "            'Archivo': 'archivo'\n",
    "        }, inplace=True)\n",
    "        \n",
    "        # Agregar la columna 'fuente' con un valor por defecto (si es necesario)\n",
    "        df['fuente'] = '091'  # Cambia 'nombre_fuente' por el valor que corresponda\n",
    "        return df\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: La columna {e} no se encuentra en el DataFrame.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al transformar el df: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformar_df_lab_citopat(df):\n",
    "    try:\n",
    "        # Definir las funciones y columnas a aplicar\n",
    "        df[['identificacion',  'Fecha de Informe', 'Fecha de Toma de Muestra', 'Nombre del Paciente']] = df[\n",
    "            ['Identificacion',  'Fecha de Informe', 'Fecha de Toma de Muestra', 'Nombre del Paciente']].astype(str)\n",
    "        funciones = {\n",
    "            'clean_special_characters': ['Diagnostico'],\n",
    "            'remove_points': ['Identificacion',  'Fecha de Informe', 'Fecha de Toma de Muestra', 'Nombre del Paciente'],\n",
    "            'transformate_date': ['Fecha de Informe', 'Fecha de Toma de Muestra']\n",
    "        }\n",
    "        \n",
    "        # Aplicar las funciones a las columnas\n",
    "        for funcion, columnas in funciones.items():\n",
    "            for columna in columnas:\n",
    "                df[columna] = df[columna].apply(eval(funcion))\n",
    "    except Exception as e:\n",
    "        print(f\"Error al transformar el df: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2 import sql\n",
    "from psycopg2.extras import execute_batch\n",
    "import psycopg2\n",
    "\n",
    "def cargar_dfpaciente(df, nombre_tabla, connection_params, columna_id='id_paciente', etiqueta_nuevo=1):\n",
    "    \"\"\"\n",
    "    Carga un DataFrame a una tabla PostgreSQL, evitando duplicados y marcando registros nuevos con etiqueta=1.\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    registros_insertados = 0\n",
    "    \n",
    "    try:\n",
    "        # 1. Conectar a la base de datos\n",
    "        conn = psycopg2.connect(**connection_params)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # 2. Obtener columnas existentes en la tabla destino\n",
    "        query_columnas = sql.SQL(\"\"\"\n",
    "            SELECT column_name \n",
    "            FROM information_schema.columns \n",
    "            WHERE table_name = %s\n",
    "        \"\"\")\n",
    "        cursor.execute(query_columnas, [nombre_tabla])\n",
    "        columnas_bd = [col[0] for col in cursor.fetchall()]\n",
    "        \n",
    "        # 3. Filtrar columnas del DataFrame que existan en la tabla\n",
    "        columnas_comunes = [col for col in df.columns if col in columnas_bd]\n",
    "        df_filtrado = df[columnas_comunes].copy()\n",
    "        \n",
    "        # 4. Agregar la columna 'etiqueta' con valor fijo etiqueta_nuevo (=1)\n",
    "        df_filtrado['etiqueta'] = etiqueta_nuevo\n",
    "\n",
    "        # 5. Preparar columnas para insertar\n",
    "        columnas_insert = list(df_filtrado.columns)\n",
    "        \n",
    "        placeholders = ', '.join(['%s'] * len(columnas_insert))\n",
    "        conflict_target = columna_id  # La columna que tiene restricción UNIQUE o PRIMARY KEY\n",
    "        \n",
    "        query_insert = sql.SQL(\"\"\"\n",
    "            INSERT INTO {tbl} ({cols}) \n",
    "            VALUES ({vals})\n",
    "            ON CONFLICT ({conflict_col}) DO NOTHING\n",
    "        \"\"\").format(\n",
    "            tbl=sql.Identifier(nombre_tabla),\n",
    "            cols=sql.SQL(', ').join(map(sql.Identifier, columnas_insert)),\n",
    "            vals=sql.SQL(placeholders),\n",
    "            conflict_col=sql.Identifier(conflict_target)\n",
    "        )\n",
    "        \n",
    "        # 6. Insertar en bloques\n",
    "        datos_a_insertar = [tuple(row) for row in df_filtrado[columnas_insert].values]\n",
    "        execute_batch(cursor, query_insert, datos_a_insertar, page_size=100)\n",
    "        \n",
    "        registros_insertados = cursor.rowcount\n",
    "        conn.commit()\n",
    "        print(f\"Insertados {registros_insertados} registros nuevos en {nombre_tabla}.\")\n",
    "        \n",
    "        return (True, registros_insertados)\n",
    "        \n",
    "    except Exception as e:\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "        print(f\"Error al cargar datos en {nombre_tabla}: {str(e)}\")\n",
    "        return (False, 0)\n",
    "        \n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def agregar_fuente(df: pd.DataFrame, nombre_fuente: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Agrega una columna 'fuente' al DataFrame con el valor proporcionado.\n",
    "\n",
    "    Parámetros:\n",
    "    - df: DataFrame original\n",
    "    - nombre_fuente: nombre de la fuente a agregar en la nueva columna\n",
    "\n",
    "    Retorna:\n",
    "    - Un nuevo DataFrame con la columna 'fuente' agregada\n",
    "    \"\"\"\n",
    "    df = df.copy()  # Evitar modificar el original\n",
    "    df[\"fuente\"] = nombre_fuente\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def agregar_observacion(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Crea una nueva columna 'observacion' a partir de la concatenación de:\n",
    "    'comentarios', 'descripcion_microscopica', 'descripcion_macroscopica' y 'diagnostico',\n",
    "    separando cada parte con el nombre de la columna en mayúsculas seguido de ':'.\n",
    "\n",
    "    Si alguna de las columnas no existe, se agrega con valores vacíos.\n",
    "\n",
    "    Parámetros:\n",
    "    - df: DataFrame original\n",
    "\n",
    "    Retorna:\n",
    "    - DataFrame con la nueva columna 'observacion'\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Lista de columnas necesarias\n",
    "    columnas_necesarias = [\n",
    "        \"comentarios\", \n",
    "        \"descripcion_microscopica\", \n",
    "        \"descripcion_macroscopica\", \n",
    "        \"diagnostico\"\n",
    "    ]\n",
    "\n",
    "    # Verificar y crear columnas faltantes con valores vacíos\n",
    "    for col in columnas_necesarias:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"\"\n",
    "\n",
    "    # Rellenar nulos con cadena vacía\n",
    "    for col in columnas_necesarias:\n",
    "        df[col] = df[col].fillna(\"\")\n",
    "\n",
    "    # Concatenar con formato\n",
    "    df[\"observacion\"] = (\n",
    "        \"COMENTARIOS: \" + df[\"comentarios\"].astype(str).str.strip() + \"| \" +\n",
    "        \"DESCRIPCION_MICROSCOPICA: \" + df[\"descripcion_microscopica\"].astype(str).str.strip() + \"| \" +\n",
    "        \"DESCRIPCION_MACROSCOPICA: \" + df[\"descripcion_macroscopica\"].astype(str).str.strip() + \"| \" +\n",
    "        \"DIAGNOSTICO: \" + df[\"diagnostico\"].astype(str).str.strip()\n",
    "    ).str.strip()\n",
    "\n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
